{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the dataset\ndataset_name = \"SKNahin/bengali-transliteration-data\"\ndataset = load_dataset(dataset_name)\n\n# Split the dataset into training and validation subsets (80/20 split) using Hugging Face's built-in method\ndataset_split = dataset['train'].train_test_split(test_size=0.2, seed=42)\n\n# Extract the training and validation sets\ntrain_data = dataset_split['train']\nval_data = dataset_split['test']\n\n# Check the split\nprint(f\"Training data size: {len(train_data)}\")\nprint(f\"Validation data size: {len(val_data)}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-21T12:49:17.300125Z","iopub.execute_input":"2024-12-21T12:49:17.300510Z","iopub.status.idle":"2024-12-21T12:49:19.535659Z","shell.execute_reply.started":"2024-12-21T12:49:17.300478Z","shell.execute_reply":"2024-12-21T12:49:19.534677Z"}},"outputs":[{"name":"stdout","text":"Training data size: 4004\nValidation data size: 1002\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ncheckpoint = \"google-t5/t5-small\"\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:10:36.199788Z","iopub.execute_input":"2024-12-21T13:10:36.200169Z","iopub.status.idle":"2024-12-21T13:10:40.139075Z","shell.execute_reply.started":"2024-12-21T13:10:36.200138Z","shell.execute_reply":"2024-12-21T13:10:40.138165Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3a3120c9aa747979f3d0404072b83d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e4e0b3563a447dabc064d640026a560"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62a40b2164e94b23b9d715a2232726bd"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom datasets import load_dataset\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\n\n# Function to tokenize the data\ndef tokenize_function(examples):\n    # Tokenize both Banglish and Bengali text (you may adjust the column names as per your dataset)\n    inputs = tokenizer(examples['bn'], padding=\"max_length\", truncation=True, max_length=128)\n    targets = tokenizer(examples['rm'], padding=\"max_length\", truncation=True, max_length=128)\n    \n    # Add the tokenized inputs and targets to the dataset\n    return {\n        'input_ids': inputs['input_ids'],\n        'attention_mask': inputs['attention_mask'],\n        'labels': targets['input_ids']  # For seq2seq tasks, labels should be the target sequence\n    }\n\n# Apply the tokenization to the train and validation sets\ntrain_data = train_data.map(tokenize_function, batched=True)\nval_data = val_data.map(tokenize_function, batched=True)\n\n# Check the tokenized data\nprint(train_data[3])\nprint(val_data[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:11:12.042744Z","iopub.execute_input":"2024-12-21T13:11:12.043156Z","iopub.status.idle":"2024-12-21T13:11:13.212574Z","shell.execute_reply.started":"2024-12-21T13:11:12.043127Z","shell.execute_reply":"2024-12-21T13:11:13.211333Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4004 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"008a4f62159c4f09b927ac8474933f4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1002 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cab7531e6b014fc9bc9d917165ed8a71"}},"metadata":{}},{"name":"stdout","text":"{'bn': 'ভাই...আর ২৪ আওয়ার ওয়েট করেন..আমার এফবি আইডি ব্যাক আসবে আমি রিকুয়েস্ট পাঠায়া দিছি...', 'rm': 'vai…ar 24 hour wait koren..amar fb id back ashbe ami request pathaia disi…', 'input_ids': [3, 2, 233, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 5, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 233, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [409, 23, 233, 291, 997, 1781, 1749, 3, 5543, 35, 5, 5, 9, 1635, 3, 89, 115, 3, 23, 26, 223, 3, 3198, 346, 3, 3690, 1690, 2071, 9, 23, 9, 1028, 23, 233, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n{'bn': 'ভালো করে ট্রাই করেন পাবেন..', 'rm': 'valo kore trai koren paben..', 'input_ids': [3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 5, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [3, 2165, 32, 3, 5543, 15, 13379, 3, 5543, 35, 2576, 115, 35, 5, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from transformers import DataCollatorForSeq2Seq\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:11:42.117461Z","iopub.execute_input":"2024-12-21T13:11:42.117873Z","iopub.status.idle":"2024-12-21T13:11:42.122262Z","shell.execute_reply.started":"2024-12-21T13:11:42.117841Z","shell.execute_reply":"2024-12-21T13:11:42.121214Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:12:32.363277Z","iopub.execute_input":"2024-12-21T13:12:32.363675Z","iopub.status.idle":"2024-12-21T13:12:35.693899Z","shell.execute_reply.started":"2024-12-21T13:12:32.363643Z","shell.execute_reply":"2024-12-21T13:12:35.692737Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e12c92e30984e198d7a795e36afb044"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"240c59037c9d46b6be93cc7567359155"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf032c824d424159a8fd44ae5f73783e"}},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"from evaluate import load\n\n# Load the BLEU metric\nmetric = load(\"sacrebleu\")\n\ndef compute_metrics(pred):\n    \"\"\"\n    Compute metrics for the Seq2Seq task.\n    Args:\n        pred: The predictions from the trainer, containing logits and labels.\n    Returns:\n        dict: A dictionary of computed metrics.\n    \"\"\"\n    # Decode predictions and references\n    predictions = pred.predictions\n    labels = pred.label_ids\n\n    # Replace -100 in labels as the tokenizer pads with -100\n    labels = [[l for l in label if l != -100] for label in labels]\n    \n    # Convert token IDs to strings\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    # Compute the metric\n    result = metric.compute(predictions=decoded_preds, references=[[ref] for ref in decoded_labels])\n\n    # Return the BLEU score (or other metrics if needed)\n    return {\"bleu\": result[\"score\"]}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"dhongi\",\n    eval_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    weight_decay=0.01,\n    save_total_limit=3,\n    num_train_epochs=2,\n    predict_with_generate=True,\n    fp16=True, #change to bf16=True for XPU\n    push_to_hub=False,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=val_data,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"translator = pipeline(\"translation_inputs_to_targets\", model=checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:32:32.155024Z","iopub.execute_input":"2024-12-21T15:32:32.155401Z","iopub.status.idle":"2024-12-21T15:32:33.049706Z","shell.execute_reply.started":"2024-12-21T15:32:32.155374Z","shell.execute_reply":"2024-12-21T15:32:33.048856Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"banglish_text = \"আমি টেস্ট করেই কোড দিছি…\"\n\n# Perform translation\ntranslated_text = translator(banglish_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:33:42.841704Z","iopub.execute_input":"2024-12-21T15:33:42.842058Z","iopub.status.idle":"2024-12-21T15:33:43.188741Z","shell.execute_reply.started":"2024-12-21T15:33:42.842033Z","shell.execute_reply":"2024-12-21T15:33:43.187876Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"print(\"translated_text\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:35:33.680499Z","iopub.execute_input":"2024-12-21T15:35:33.680848Z","iopub.status.idle":"2024-12-21T15:35:33.684320Z","shell.execute_reply.started":"2024-12-21T15:35:33.680822Z","shell.execute_reply":"2024-12-21T15:35:33.683609Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:32:39.108315Z","iopub.execute_input":"2024-12-21T15:32:39.108718Z","iopub.status.idle":"2024-12-21T15:32:39.112732Z","shell.execute_reply.started":"2024-12-21T15:32:39.108683Z","shell.execute_reply":"2024-12-21T15:32:39.111904Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:21:33.661668Z","iopub.execute_input":"2024-12-21T13:21:33.662064Z","iopub.status.idle":"2024-12-21T13:21:34.811368Z","shell.execute_reply.started":"2024-12-21T13:21:33.662025Z","shell.execute_reply":"2024-12-21T13:21:34.810247Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T12:58:31.636735Z","iopub.execute_input":"2024-12-21T12:58:31.637141Z","iopub.status.idle":"2024-12-21T12:58:42.673988Z","shell.execute_reply.started":"2024-12-21T12:58:31.637109Z","shell.execute_reply":"2024-12-21T12:58:42.673043Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:00:12.422354Z","iopub.execute_input":"2024-12-21T13:00:12.422764Z","iopub.status.idle":"2024-12-21T13:00:12.430135Z","shell.execute_reply.started":"2024-12-21T13:00:12.422732Z","shell.execute_reply":"2024-12-21T13:00:12.429005Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T13:00:28.311436Z","iopub.execute_input":"2024-12-21T13:00:28.311829Z","iopub.status.idle":"2024-12-21T13:00:37.295729Z","shell.execute_reply.started":"2024-12-21T13:00:28.311797Z","shell.execute_reply":"2024-12-21T13:00:37.294621Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T15:36:01.508871Z","iopub.execute_input":"2024-12-21T15:36:01.509233Z","iopub.status.idle":"2024-12-21T15:36:01.512747Z","shell.execute_reply.started":"2024-12-21T15:36:01.509202Z","shell.execute_reply":"2024-12-21T15:36:01.511843Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}